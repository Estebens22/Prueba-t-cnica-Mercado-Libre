# Mercado Libre â€“ New vs Used Classification

## ğŸ“Œ Objetivo

Construir un modelo de Machine Learning capaz de clasificar publicaciones de Mercado Libre como **`new`** o **`used`**, utilizando exclusivamente informaciÃ³n disponible al momento de la publicaciÃ³n y priorizando un enfoque **escalable, interpretable y production-ready**.

---

## ğŸ“‚ Estructura del proyecto
```
ml/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ MLA_100k.jsonlines       # Dataset original
â”‚   â””â”€â”€ README.md                # DescripciÃ³n del dataset
â”œâ”€â”€ features/
â”‚   â””â”€â”€ feature_builder.py       # Feature engineering
â”œâ”€â”€ models/
â”‚   â””â”€â”€ new_used_model.pkl       # Modelo entrenado
â”œâ”€â”€ train.py                     # Entrenamiento
â”œâ”€â”€ evaluate.py                  # EvaluaciÃ³n
â””â”€â”€ report.md                    # AnÃ¡lisis y conclusiones
```

---

## ğŸ“Š Dataset

- **Fuente:** Publicaciones reales de Mercado Libre (MLA)
- **Formato:** JSON Lines
- **TamaÃ±o:** ~100.000 publicaciones
- **Target:** `condition` â†’ `{ new, used }`

El dataset contiene informaciÃ³n estructural del marketplace como precio, logÃ­stica, tipo de publicaciÃ³n, imÃ¡genes, categorÃ­a, texto del tÃ­tulo, entre otros.

---

## ğŸ§  Enfoque de la soluciÃ³n

Se priorizÃ³ un enfoque **prÃ¡ctico y realista**, alineado con escenarios de producciÃ³n:

- âŒ Sin TF-IDF pesado ni modelos deep learning
- âœ… Features estructurales y de dominio del marketplace
- âœ… Modelo interpretable y eficiente
- âœ… Sin data leakage

---

## âš™ï¸ Feature Engineering

Las features se agrupan en cuatro grandes categorÃ­as:

### 1ï¸âƒ£ Precio y performance
- `price_log`: log(1 + price)
- `sold_quantity_log`: log(1 + sold_quantity)

### 2ï¸âƒ£ Visual y stock
- `num_images_log`
- `has_stock`

### 3ï¸âƒ£ LogÃ­stica y pago
- `free_shipping`
- `accepts_mp`
- `shipping_mode`

### 4ï¸âƒ£ SeÃ±ales semÃ¡nticas livianas
- `kw_new`, `kw_used` (keywords en tÃ­tulo)
- `title_len`

### 5ï¸âƒ£ Estructura del marketplace
- `category_id`
- `listing_type_id`

Estas features son **baratas de computar**, estables en el tiempo y altamente explicativas del comportamiento real del marketplace.

---

## ğŸ¤– Modelo

- **Algoritmo:** LightGBM (Gradient Boosted Trees)
- **Motivos de elecciÃ³n:**
  - Manejo eficiente de variables heterogÃ©neas
  - Buen desempeÃ±o sin heavy feature scaling
  - Interpretabilidad
  - Escalabilidad en producciÃ³n

- **Preprocesamiento:**
  - NumÃ©ricas: `StandardScaler`
  - CategÃ³ricas: `TargetEncoder`
  - Booleanas: passthrough

---

## ğŸ“ˆ EvaluaciÃ³n

La evaluaciÃ³n se realizÃ³ sobre un **hold-out fijo de 10.000 publicaciones**, separado del entrenamiento.

### Resultados finales:

```
| MÃ©trica | Valor |
|------|------|
| Accuracy | **0.8862** |
| Recall (USED) | **0.8742** |
| F1-score macro | **0.89** |

          precision    recall  f1-score   support

       new       0.89      0.90      0.89
      used       0.88      0.87      0.88

accuracy                           0.89
```

Estos resultados superan holgadamente el umbral solicitado en la consigna.

---

## â–¶ï¸ EjecuciÃ³n

### Entrenamiento
```
python train.py
```

### EvaluaciÃ³n
```
python evaluate.py
```

ğŸ§© Decisiones clave
	â€¢	Se evitÃ³ el uso de texto pesado para garantizar latencia baja y escalabilidad.
	â€¢	Se utilizaron seÃ±ales reales del negocio (logÃ­stica, tipo de publicaciÃ³n, performance histÃ³rica).
	â€¢	Se mantuvo una separaciÃ³n clara entre feature engineering, modelo y evaluaciÃ³n.
	â€¢	Se priorizÃ³ un diseÃ±o reproducible y fÃ¡cil de mantener.

â¸»

ğŸ“Œ ConclusiÃ³n

El modelo logra un desempeÃ±o sÃ³lido utilizando Ãºnicamente informaciÃ³n disponible al momento de la publicaciÃ³n, con un enfoque alineado a estÃ¡ndares reales de producciÃ³n en marketplaces de gran escala.

La soluciÃ³n es:
	â€¢	âœ”ï¸ Precisa
	â€¢	âœ”ï¸ Escalable
	â€¢	âœ”ï¸ Interpretable
	â€¢	âœ”ï¸ FÃ¡cil de mantener

â¸»

âœï¸ Autor

Esteban Baquero
Tech Lead / AI Engineer
Prueba tÃ©cnica â€“ Mercado Libre